\chapter{Wstęp}
\section{Wprowadzenie}

Pandemia COVID-19 oraz zdobywające coraz większą popularność zdalne formy zatrudnienia obrazują jak
ważna jest rola internetowych połączeń wideo we współczesnym społeczeństwie. W wielu przypadkach
kontakt "twarzą w twarz" jest preferowalny, a nawet niezbędny do realizacji pewnych zadań. W takich
wypadkach niezawodność i jakość transmisji wideo stają się bardzo ważnymi problemami.

W ciągu ostatnich 20 lat poczynione zostały ogromne postępy w rozwoju infrastruktury internetowej w
Polsce. Liczba internautów wzrosła z 16 mln w roku 2011 do 29,7 mln w roku 2021. Dzięki
rozpowszechnieniu i coraz szerszemu użyciu technologii światłowodowej znacząco wzrosły szerokości
pasm, dzięki czemu możliwe stało się transmitowanie jeszcze większej ilości danych w tym samym
czasie, a także znaczącemu obniżeniu uległy opóźnienia, dzięki czemu mogły powstać i rozpowszechnić
się aplikacje wykorzustujące internet do komunikacji w czasie rzeczywistym, takie jak gry wideo oraz
komunikatory internetowe. Rozwój internetu mobilnego umożliwił dostęp do szerokopasmowego internetu
na terenach mniej zamożnych i rzadziej zaludnionych.

W porównaniu do tak ogromnego rozwoju internetu, postępy w jakości transmisji wideo były jednak
skromne. Rozwój infrastruktury internetowej zapewnił większą niezawodność i wyższe szerokości pasma
dzięki czemu transmisje wideo mogły zawierać więcej danych, usprawniając jakość, jednak bardzo
szybko trafiliśmy na sufit, który ograniczył postępy w poprawie jakości transmisji wideo:

\begin{itemize}
    \item Szerokości pasma podawane przez dostawców internetowych są wartościami optymistycznymi,
          maksymalne wykorzystanie pasma jest możliwe jeżeli dane wysyłane przez łącze jest
          odpowiednio wysoko buforowane, czyli jeżeli istnieje duża kolejka danych która może zostać
          wysłana przez łącze naraz. Ta potrzeba kolejkowania sprawia że efektywna szerokość łącza
          jest mniejsza dla aplikacji czasu rzeczywistego niż innych aplikacji. Oczywiście aplikacje
          czasu rzeczywistego też wykorzystują buforowanie, ale ponieważ opóźnienie jest w ich
          wypadku kluczowe i wysłane dane muszą trafić do odbiorcy w ciągu ~500ms od ich wysłania
          przez odbiorcę, buforowanie jakie mogą one robić jest ograniczone.
          
    \item O ile szerokość pasma mogąca być wykorzystana do transmisji wideo nie jest już czynnikiem
          limitującym dla osób prywatnych mających dostęp do połączeń światłowodowych często
          zapewniających prędkości ponad 100Mb/s, to nadal są one ograniczeniem dla internetowych
          dostawców wideo, jak np. Youtube, Twitch, lub Netflix. Youtube po otrzymaniu filmu
          wysłanego przez użytkownika udostępnia jego jeszcze bardziej skompresowaną wersję, Twitch
          ogranicza bitrate streamów 1080p do 4.5Mb/s, a w trakcie pandemii łączny udział Netflixa w
          internecie był tak duży, że ten musiał ograniczać jakość strumieni wideo
          (https://www.forbes.com/sites/johnarcher/2020/05/12/netflix-starts-to-lift-its-coronavirus-streaming-restrictions/)
          
    \item Internet mobilny poprawił dostęp do internetu na terenach mniej zamożnych i mniej gęsto
          zaludnionych, jednak nie jest on w stanie zastąpić światłowodu. Internet mobilny jest
          wolniejszy od przewodowego, charakteryzuje się też większymi opóźnieniami i większą podatnością
          na zakłócenia. W takich warunkach nie jest możliwe poprawienie jakości obrazu przez zwiększanie
          obiętości strumienia wideo, i trzeba polegać na lepszych technikach kompresji.
\end{itemize}

Mając na uwadze powyższe, pojawiają się pytania: "Czy możliwe jest jeszcze bardziej poprawić jakość transmisji
wideo w internecie? W jaki sposób to zrobić jeżeli zwiększanie ilości danych jest problematyczne i
podlega malejącym zwrotom?".

Odpowiedź można znaleźć w lepszych metodach kompresji wideo. Aktualny powszechnie używany standard,
opracowany przez MPEG standard AVC (Advanced Video Coding) jest używany od roku 2003, a jego
następca, HEVC nie uzyskał tak szerokiej adopcji, głównie za sprawą zbyt restrykcyjnych zapisów
patentowych i licencyjnych.

Niezadowolone z kształtu HEVC, firmy technologiczne takie jak Google, Mozilla, Microsoft, Apple,
etc. założyły konsorcjum \emph{Alliance for Open Media (AOM)}, które w roku 2018 wytworzyło AV1,
otwarty i darmowy kodek wideo, będący następcą kodeka VP9 wytworzonego przez Google. AV1 jest
aktualnie w fazie adopcji przez dostawców zawartości wideo oraz producentów sprzętu.

AV1 dzięki nowym technikom osiąga lepszą kompresję danych, co ma zastosowanie dla dostawców wideo,
którzy dzięki nowemu kodekowi będą w stanie zapewnić oglądającym lepszy obraz jednocześnie
zmniejszając obiętość danych do wysłania. Nie jest jednak jasne czy AV1 ma zastosowanie w
internetowych komunikatorach wideo pomiędzy dwoma użytkownikami używającymi do transmisji komputerów
PC lub urządzeń mobilnych. Najważniejszą rzeczą w połączeniach wideo czasu rzeczywistego jest
opóźnienie, jakość obrazu pełni rolę drugorzędną dopóki spełnia ona pewne minimum oczekiwań
uczestników. Aby zapewnić wyższy poziom kompresji niezbędne są bardziej złożone i obliczeniowo
intensywne algorytmy, co może pogorszyć opóźnienia takiego połączenia. Aby usprawnić proces
kompresji/dekompresji używa się także akceleratorów sprzętowych, będących zazwyczaj częścią układu
graficznego danego urządzenia, jednak urządzenia wyposażone we wsparcie dla AV1 zaczęły się pojawiać
relatywnie niedawno.

Czy zatem AV1 ma zastosowanie do transmisji wideo w czasie rzeczywistym?

\section{Cel i zakres pracy}
Celem niniejszej pracy jest analiza połączeń wideo czasu rzeczywistego w każdym ich etapie, badanie
procesów składających się na nie, i wreszcie utworzenie internetowego komunikatora wideo
wykorzystującego poznane koncepty i rozwiązania.

Najpierw wykonana zostanie aplikacja webowa wykorzystująca dostępne w przeglądarkach API WebRTC,
zapewniające przeglądarkom możliwości obsługiwania strumieni multimedialnych czasu rzeczywistego i
pozwalające na nawiązywanie połączeń peer-to-peer z innymi klientami, dzięki wykorzystaniu
mechanizmów STUN/TURN. Na przykładzie tej aplikacji, zaprezentowane zostaną procesy i protokoły
umożliwiające nawiązywanie połączeń wideo peer-to-peer.

Następnie, za pomocą języka programowania Rust, wykonana zostanie aplikacja okienkowa na systemy
Linux, prezentująca na niższym poziomie przechwytywanie obrazu i dźwięku, kompresję strumieni
wideo/audio oraz transmisję danych pomiędzy klientami. Aplikacja będzie nawiązywać połączenia wideo
peer-to-peer, a także będzie wykorzystywać kodek AV1 do kompresji wideo.

\section{Układ pracy - DO ZMIANY}

W rozdziale 2 omówione zostaną koncepty i metody związane ze strumieniowaniem wideo. Przedstawiony
zostanie uproszczony opis procesu transmisji wideo w czasie rzeczywistym, od pobrania klatki obrazu
przez kamerę internetową, do wyświetlenia tejże klatki na monitorze rozmówcy. Poruszone zostaną
problemy związane z transmisją wideo przez sieć internetową, np. problem ustanowienia kanału P2P
pomiędzy klientami za siecią NAT, negocjowanie sesji pomiędzy klientami, adaptive bitrate, etc.

W rozdziale 3 omówiony zostanie projekt WebRTC i jego protokoły składowe, czytelnik dowie się
również w jaki sposób WebRTC rozwiązuje problemy poruszone we wcześniejszym rozdziale i tym samym
niezwykle upraszcza tworzenie multimedialnych aplikacji webowych.

W rozdziale 4 zaprezentowana zostanie aplikacja webowa wykorzystująca WebRTC, nastąpi ogólny
przegląd wykorzystywanych technologii oraz oprogramowania, zaprezentowane zostaną fragmenty kodu
źródłowego realizujące kluczowe procesy nawiązywania połączenia poruszone we wcześniejszym
rozdziale. Wykonana zostanie dokładna analiza ruchu sieciowego pomiędzy hostami i uzupełniony
zostanie proces nawiązywania połączenia WebRTC poruszony we wcześniejszym rozdziale, zobrazowany
konkretnym przykładem.

W rozdziale 5 omówione zostaną problemy, generalne mechanizmy i koncepty związane z kompresją wideo,
kontenery, strumienie oraz ich muxowanie do kontenerów, rodzaje kodeków wideo, proces
enkodowania/dekodowania, sprzętowe oraz programowe implementacje koderów.

W rozdziale 6 poruszone zostaną problemy i rozwiązania związane ze strumieniowaniem AV1.
Zrealizowane zostanie "zejście na niższy poziom", co pozwoli na głębsze zapoznanie się z krokami
realizowanymi celem przygotowania strumienia wideo do transmisji oraz wyświetlenia przychodzącego
wideo na ekranie monitora. Zrealizowane zostanie min.: zastąpienie całości lub części stosu WebRTC
rozwiązaniami natywnymi, oferowanymi przez sprzęt lub system operacyjny, wyeliminowanie abstrakcji
oferowanych przez przeglądarkę, wybór optymalnego kodera oraz jego parametrów, wybór technologii
GUI, zaplanowanie i omówienie procesu strumieniowania z rozdziału 1szego, wraz z elementami które
będą go realizowały.

W rozdziale 7 zaprezentowana zostanie wykonana aplikacja desktopowa wykorzystująca biblioteki oraz
inne rozwiązania udostępniane przez system operacyjny. Omówienie architektury, wykorzystywanych
technologii i fragmentów kodu aplikacji okienkowej. Zaprezentowanie wybranych etapów procesu
strumieniowania realizowanych przez aplikację.
