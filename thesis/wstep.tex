\chapter{Wstęp}
\section{Wprowadzenie}

Pandemia COVID-19 oraz zdobywające coraz większą popularność zdalne formy zatrudnienia obrazują jak
ważna jest rola internetowych połączeń wideo we współczesnym społeczeństwie. W wielu przypadkach
kontakt "twarzą w twarz" jest preferowalny, a nawet niezbędny do realizacji pewnych zadań. W takich
wypadkach niezawodność i jakość transmisji wideo stają się bardzo ważnymi problemami.

W ciągu ostatnich 20 lat poczynione zostały ogromne postępy w rozwoju infrastruktury internetowej w
Polsce. Liczba internautów wzrosła z 16 mln w roku 2011 do 29,7 mln w roku 2021. Dzięki
rozpowszechnieniu i coraz szerszemu użyciu technologii światłowodowej znacząco wzrosły szerokości
pasm, dzięki czemu możliwe stało się transmitowanie jeszcze większej ilości danych w tym samym
czasie, a także znaczącemu obniżeniu uległy opóźnienia, dzięki czemu mogły powstać i rozpowszechnić
się aplikacje wykorzustujące internet do komunikacji w czasie rzeczywistym, takie jak gry wideo oraz
komunikatory internetowe. Rozwój internetu mobilnego umożliwił dostęp do szerokopasmowego internetu
na terenach mniej zamożnych i rzadziej zaludnionych.

W porównaniu do tak ogromnego rozwoju internetu, postępy w jakości transmisji wideo były jednak
skromne. Rozwój infrastruktury internetowej zapewnił większą niezawodność i wyższe szerokości pasma
dzięki czemu transmisje wideo mogły zawierać więcej danych, usprawniając jakość, jednak bardzo
szybko trafiliśmy na sufit, który ograniczył postępy w poprawie jakości transmisji wideo:

\begin{itemize}
      \item Szerokości pasma podawane przez dostawców internetowych są wartościami optymistycznymi,
            maksymalne wykorzystanie pasma jest możliwe jeżeli dane wysyłane przez łącze jest
            odpowiednio wysoko buforowane, czyli jeżeli istnieje duża kolejka danych która może
            zostać wysłana przez łącze naraz. Ta potrzeba kolejkowania sprawia że efektywna
            szerokość łącza jest mniejsza dla aplikacji czasu rzeczywistego niż innych aplikacji.
            Oczywiście aplikacje czasu rzeczywistego też wykorzystują buforowanie, ale ponieważ
            opóźnienie jest w ich wypadku kluczowe i wysłane dane muszą trafić do odbiorcy w ciągu
            ~500ms od ich wysłania przez odbiorcę, buforowanie jakie mogą one robić jest
            ograniczone.
            
      \item O ile szerokość pasma mogąca być wykorzystana do transmisji wideo nie jest już
            czynnikiem limitującym dla osób prywatnych mających dostęp do połączeń światłowodowych
            często zapewniających prędkości ponad 100Mb/s, to nadal są one ograniczeniem dla
            internetowych dostawców wideo, jak np. Youtube, Twitch, lub Netflix. Youtube po
            otrzymaniu filmu wysłanego przez użytkownika udostępnia jego jeszcze bardziej
            skompresowaną wersję, Twitch ogranicza bitrate streamów 1080p do 4.5Mb/s, a w trakcie
            pandemii łączny udział Netflixa w internecie był tak duży, że ten musiał ograniczać
            jakość strumieni wideo
            (https://www.forbes.com/sites/johnarcher/2020/05/12/netflix-starts-to-lift-its-coronavirus-streaming-restrictions/)
            
      \item Internet mobilny poprawił dostęp do internetu na terenach mniej zamożnych i mniej gęsto
            zaludnionych, jednak nie jest on w stanie zastąpić światłowodu. Internet mobilny jest
            wolniejszy od przewodowego, charakteryzuje się też większymi opóźnieniami i większą
            podatnością na zakłócenia. W takich warunkach nie jest możliwe poprawienie jakości
            obrazu przez zwiększanie obiętości strumienia wideo, i trzeba polegać na lepszych
            technikach kompresji.
\end{itemize}

Mając na uwadze powyższe, pojawiają się pytania: "Czy możliwe jest jeszcze bardziej poprawić jakość
transmisji wideo w internecie? W jaki sposób to zrobić jeżeli zwiększanie ilości danych jest
problematyczne i podlega malejącym zwrotom?".

Odpowiedź można znaleźć w lepszych metodach kompresji wideo. Aktualny powszechnie używany standard,
opracowany przez MPEG standard AVC (Advanced Video Coding) jest używany od roku 2003, a jego
następca, HEVC nie uzyskał tak szerokiej adopcji, głównie za sprawą zbyt restrykcyjnych zapisów
patentowych i licencyjnych.

Niezadowolone z kształtu HEVC, firmy technologiczne takie jak Google, Mozilla, Microsoft, Apple,
etc. założyły konsorcjum \emph{Alliance for Open Media (AOM)}, które w roku 2018 wytworzyło AV1,
otwarty i darmowy kodek wideo, będący następcą kodeka VP9 wytworzonego przez Google. AV1 jest
aktualnie w fazie adopcji przez dostawców zawartości wideo oraz producentów sprzętu.

AV1 dzięki nowym technikom osiąga lepszą kompresję danych, co ma zastosowanie dla dostawców wideo,
którzy dzięki nowemu kodekowi będą w stanie zapewnić oglądającym lepszy obraz jednocześnie
zmniejszając obiętość danych do wysłania. Nie jest jednak jasne czy AV1 ma zastosowanie w
internetowych komunikatorach wideo pomiędzy dwoma użytkownikami używającymi do transmisji komputerów
PC lub urządzeń mobilnych. Najważniejszą rzeczą w połączeniach wideo czasu rzeczywistego jest
opóźnienie, jakość obrazu pełni rolę drugorzędną dopóki spełnia ona pewne minimum oczekiwań
uczestników. Aby zapewnić wyższy poziom kompresji niezbędne są bardziej złożone i obliczeniowo
intensywne algorytmy, co może pogorszyć opóźnienia takiego połączenia. Aby usprawnić proces
kompresji/dekompresji używa się także akceleratorów sprzętowych, będących zazwyczaj częścią układu
graficznego danego urządzenia, jednak urządzenia wyposażone we wsparcie dla AV1 zaczęły się pojawiać
relatywnie niedawno.

Czy zatem AV1 ma zastosowanie do transmisji wideo w czasie rzeczywistym?

\section{Cel i zakres pracy}
Celem niniejszej pracy jest analiza połączeń wideo czasu rzeczywistego w każdym ich etapie, badanie
procesów składających się na nie, i wreszcie utworzenie internetowego komunikatora wideo
wykorzystującego poznane koncepty i rozwiązania.

Najpierw wykonana zostanie aplikacja webowa wykorzystująca dostępne w przeglądarkach API WebRTC,
zapewniające przeglądarkom możliwości obsługiwania strumieni multimedialnych czasu rzeczywistego i
pozwalające na nawiązywanie połączeń peer-to-peer z innymi klientami, dzięki wykorzystaniu
mechanizmów STUN/TURN. Na przykładzie tej aplikacji, zaprezentowane zostaną procesy i protokoły
umożliwiające nawiązywanie połączeń wideo peer-to-peer.

Następnie, za pomocą języka programowania Rust, wykonana zostanie aplikacja okienkowa na systemy
Linux, prezentująca na niższym poziomie przechwytywanie obrazu i dźwięku, kompresję strumieni
wideo/audio oraz transmisję danych pomiędzy klientami. Aplikacja będzie nawiązywać połączenia wideo
peer-to-peer, a także będzie wykorzystywać kodek AV1 do kompresji wideo.

\section{Układ pracy}

W rozdziale 2 wykonana zostanie analiza wymagań, omówione zostaną wymagania funkcjonalne oraz
niefunkcjonalne tworzonego oprogramowania.

W rozdziale 3 omówione zostaną niezbędne do opanowania zagadnienia teoretyczne - poruszone zostaną
koncepty i metody związane ze strumieniowaniem wideo oraz różne problemy związane z transmisją wideo
przez sieć internetową.
% Przedstawiony zostanie uproszczony opis procesu transmisji wideo w czasie rzeczywistym, od
% pobrania klatki obrazu przez kamerę internetową, do wyświetlenia tejże klatki na monitorze
% rozmówcy.
Następnie przedstawione zostaną technologie wykorzystane w realizacji
zadania: WebRTC, GStreamer, Rust, a także zostaną omówione wykorzystane techniki programowania
asynchronicznego.

W rozdziale 4 przedstawiona zostanie koncepcja realizacji projektu, tj. plan projektu prezentujący
poszczególne części tworzonego oprogramowania oraz zachowanie tych części w relacji ze sobą.

W rozdziale 5 zaprezentowane zostaną dwie wykonane aplikacje. Pierwszą z nich jest przykładowa
aplikacja webowa wykorzystująca API WebRTC w języku Javascript wraz z wykorzystywanymi przez nią
technologiami, oraz omówionymi fragmentami kodu źródłowego realizujące kluczowe procesy nawiązywania
połączenia poruszone w rozdziale trzecim. Wykonana zostanie uproszczona analiza ruchu sieciowego
pomiędzy hostami i uzupełniony zostanie proces nawiązywania połączenia WebRTC poruszony we
wcześniejszym rozdziale, zobrazowany konkretnym przykładem.

Drugą z zaprezentowanych aplikacji jest finalna implementacja aplikacji okienkowej wideokomunikatora
Piperchat na systemy Linux. Przedstawiona zostanie struktura projektu i detale implementacji serwera
oraz klienta, diagramy przedstawiające ich strukturę oraz fragmenty kodu.

Rozdział 6 podsumowuje pracę, omawia jakie cele pracy zostały zrealizowane, przedstawia wnioski oraz
możliwe usprawnienia projektu.

